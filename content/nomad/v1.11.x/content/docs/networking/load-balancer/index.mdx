---
layout: docs
page_title: Load balancing considerations
description: >-
  Discover the available load balancing applications to deploy and
  best practices for cluster performance and high availability.
---

# Load balancing considerations

This overview provides considerations for deploying load balancers in your
Nomad plus Consul infrastructure. While reading through these scenarios,
you should evaluate what works best for your particular environment.

## Deploy load balancers as system jobs in separate datacenters

Nomad allows you to configure which [datacenter][datacenter] your node belongs
to. Using this information in the [job specification][job-spec], you can control
which datacenter you deploy your application into. You can use this technique to
isolate your load balancers by deploying them to a distinct datacenter. This
method may provide you the following advantages:

- Isolation between submitting/modifying infrastructure-related jobs vs core
  applications.

- The ability to deploy your load balancer as a [system][system] job to a
  well-defined, limited number of nodes dedicated to your infrastructure
  applications. This approach prevents the over-utilization
  of resources across the entire cluster.

## Use service scheduler with one or more instances of your load balancer

To avoid over-utilization of your cluster resources, you may want to consider
deploying your load balancer with the [service][service] scheduler and using a
[count][count] with one or more instances. If you use this approach, note the following:

- Your applications need to use service discovery to discover the load
  balancer instances in your cluster.

- You have to adjust the [resources][resources] and [count][count] of your
  load balancer instances depending on traffic and utilization.

## Use auto scaling groups with load balancers

Use [Auto Scaling Groups][asg] with [client metadata][metadata-config] to ensure
load balancer availability. Follow these steps to implement this approach:

1. Configure the group of Nomad clients that are running your load balancer to
  be part of their own autoscaling group.
1. Configure these clients with [metadata][metadata-config] unique to their
  purpose.
1. Run the load balancer job [constraining the deployment][metadata-constraint]
  to the metadata you have configured on the clients.

The preceding steps ensure that if any nodes dedicated to running your load
balancers go down, Nomad brings back up the necessary infrastructure. Also,
Nomad ensures the load balancer deploys to the correct nodes.

**Note**: Consider configuring [Dynamic Scaling][dynamic-scaling] to
automatically scale up the nodes dedicated to your load balancers based on
metrics like CPU utilization, etc.

## Resources

Deployment guides:

- [Fabio][lb-fabio]
- [HAProxy][lb-haproxy]
- [NGINX][lb-nginx]
- [Traefik][lb-traefik]

Use case tutorial:

- [Manage external traffic with application load balancing](/nomad/tutorials/load-balancing/external-application-load-balancing): Deploy an Application Load Balancer on AWS to allow external internet traffic to your internally load-balanced applications running in Nomad.

[asg]: https://docs.aws.amazon.com/autoscaling/ec2/userguide/AutoScalingGroup.html
[count]: /nomad/docs/job-specification/group#count
[datacenter]: /nomad/docs/configuration#datacenter
[dynamic-scaling]: https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-scale-based-on-demand.html
[job-spec]: /nomad/docs/job-specification/job#datacenters
[lb-fabio]: /nomad/docs/deploy/clusters/load-balance/fabio
[lb-haproxy]: /nomad/docs/deploy/clusters/load-balance/haproxy
[lb-nginx]: /nomad/docs/deploy/clusters/load-balance/nginx
[lb-traefik]: /nomad/docs/deploy/clusters/load-balance/traefik
[metadata-config]: /nomad/docs/configuration/client#meta
[metadata-constraint]: /nomad/docs/job-specification/constraint#user-specified-metadata
[resources]: /nomad/docs/job-specification/resources
[service]: /nomad/docs/concepts/scheduling/schedulers#service
[system]: /nomad/docs/concepts/scheduling/schedulers#system

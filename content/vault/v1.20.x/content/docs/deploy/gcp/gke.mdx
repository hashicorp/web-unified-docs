---
layout: docs
page_title: Deploy Vault on Google Kubernetes Engine (GKE)
description: >-
  Guide to deploying and setting up Vault on Google Kubernetes Engine (GKE).
---

# Deploy Vault on Google Kubernetes Engine (GKE)

Ypu can deploy Vault with Google Kubernetes Engine (GKE) to run Vault in a
secured and managed Kubernetes service. Google Kubernets Engine supports
standard and autopilot modes:

- **Standard mode** provides flexibility for configuring the underlying
  cluster infrastructure.
- **Autopilot mode** provides a hands-off experience for deploying an optimized
  cluster.

## Before you start

- You should be familiar with Kubernetes concepts like pods, service accounts,
  and manifests.
- You should be comfortable working with:
   - [Google Cloud projects](https://developers.google.com/workspace/guides/create-project).
   - [Google Kubernetes Engine (GKE)](https://cloud.google.com/kubernetes-engine/docs/concepts/kubernetes-engine-overview).
   - [Helm charts](https://helm.sh/docs/topics/charts).
- You must have a [Google Cloud account](https://console.cloud.google.com) with
  a project initialized and the Google container service
  (`container.googleapis.com`) enabled.
- You must have the following CLIs installed:
   - [`gcloud`](https://cloud.google.com/sdk/docs/quickstart) - Google Cloud CLI.
   - [`kubectl`](https://kubernetes.io/docs/tasks/tools/install-kubectl/) - Kubernetes CLI
   - [`helm`](https://helm.sh/docs/helm/) - Helm CLI.
- You must have [`jq`](https://jqlang.org/) installed.


## Step 1: Add the Hashicorp repo to Helm

You must have the Vault Helm chart to deploy Vault. You can add the Hashicorp
repository (`helm.releases.hashicorp.com`) with the `helm repo add` command:

```shell-session
$ helm repo add hashicorp https://helm.releases.hashicorp.com
```



## Step 2: Start a GKE cluster

1. Use the `auth login` command to log into your Google Cloud account with your
   preferred project. For example:

   ```shell-session
   $ gcloud auth login --project=<gcp_project_id>

   ```

1. Create a new Vault cluster. We recommend using a minimum of three nodes and
   autopilot mode unless you need the granularity provided by manual mode.
   For example:

   ```shell-session
   $ gcloud container clusters create-auto   \
       <cluster_name>                        \
       --min-nodes=3
   ```   
   
   While you can also create the nodes manually, autopilot manages the
   underlying infrastructure on your behalf so you can start with a smaller
   set of nodes but provisions more as needed.

Once Google Cloud creates, deploys, and confirms the health of the cluster it
modifies your `kubectl` configuration to perform any commands you issue against
the cluster.



## Step 3: Install Vault using helm

The Vault Helm chart contains all the necessary components to run Vault in
several different modes.

<Tip title="Set cluster name for Prometheus monitoring">

   If you use Prometheus for monitoring and alerting, we recommend setting the
   `cluster_name` in your HCL configuration using the `config` parameter in the
   Vault Helm chart.

</Tip>

1. Create a file named `helm-vault-raft-values.yml` with you preferred
   deployment configuration. We recommend using meaningful cluster names for
   your data clusters. For example, the following file creates a basic
   deployment configuration that deploys the Vault pods and Vault Agent Injector
   pod in the default namespace and uses Vault integrated storage :

   ```shell-session
   $ cat > helm-vault-raft-values.yml <<EOF
   server:
      affinity: ""
      ha:
         enabled: true
         raft:
            enabled: true
            setNodeId: true
            config: |
               cluster_name = "vault-integrated-storage"
               storage "raft" {
                  path    = "/vault/data/"
               }

               listener "tcp" {
                  address = "[::]:8200"
                  cluster_address = "[::]:8201"
                  tls_disable = "true"
               }
               service_registration "kubernetes" {}
   EOF
   ```

1. Use your new deployment configuration file with `helm install` to install the
   latest version of the Vault Helm chart and create your Vault server
   instances:

   ```shell-session
   $ helm install       \
      <cluster_name>    \
      <chart_reference> \
      --values <yml_config_file>
   ```
   
   For example:

   <CodeBlockConfig hideClipboard>

   ```shell-session
   $ helm install     \
      vault           \
      hashicorp/Vault \
      --values helm-vault-raft-values.yml
   ```

   </CodeBlockConfig>

## Step 4: Initialize and unseal the primary Vault pod

Vault starts [sealed](/vault/docs/concepts/seal#why) and 
[uninitialized](/vault/docs/commands/operator/init). Before Vault can receive
data, you need to initialization the new storage backend and use the provided
keys to unseal Vault.

<Warning title="Use more than one unseal key in production">

   The steps below demonstrate the unseal process with a single key.  In
   production systems, we recommend a minimum of five unseal keys with an unseal
   threshold of three keys.

</Warning>

1. Use the Kubernetes CLI to run `vault operator init` and initialize Vault and
   write the unseal keys to `cluster-keys.json`. For example, the following
   command initializes the first pod in the `vault` cluster:

   ```shell-session
   $ kubectl exec vault-0 --  \
      vault operator init     \
       -key-shares=1          \
       -key-threshold=1       \
       -format=json > cluster-keys.json
   ```

1. Create a local environment variable named `VAULT_UNSEAL_KEY` to capture the
   Vault unseal key from `cluster-keys.json`:

   ```shell-session
   $ VAULT_UNSEAL_KEY=$(cat cluster-keys.json | jq -r ".unseal_keys_b64[]")
   ```

1. Use the Kubernetes CLI to run `vault operator unseal` and unseal the Vault
   instance running on your first pod. For example, to unseal the Vault instance
   on `vault-0`:

   ```shell-session
   $ kubectl exec vault-0 -- \
      vault operator unseal ${VAULT_UNSEAL_KEY}
   ```


## Step 5: Join additional nodes to the Vault cluster

The Vault server currently running on the first pod (`vault-0`) is configured
as a high-availability cluster but only running a single node. To create a true
high-availability cluster, you need to spin up additional nodes.

1. Create a variable named `CLUSTER_ROOT_TOKEN` to capture the Vault unseal key:

   ```shell-session
   $ CLUSTER_ROOT_TOKEN=$(cat cluster-keys.json | jq -r ".root_token")
   ```

1. Use the Kubernetes CLI to run `vault login` to log into Vault with the root
   token on your first pod. For example, to log into Vault on `vault-0`:

   ```shell-session
   $ kubectl exec vault-0 -- \
      vault login ${CLUSTER_ROOT_TOKEN}
   ```

1. Use the Kubernetes CLI to run the Vault CLI `raft list-peers` command to list
   the available nodes:

   ```shell-session
   $ kubectl exec vault-0 -- \
      vault operator raft list-peers

   Node        Address        State     Voter
   ----        -------        -----     -----
   vault-0     127.0.0.2:8201 leader    true
   vault-1     127.0.0.3:8201 follower  true
   vault-2     127.0.0.4:8201 follower  true
   ```

1. Use the Kubernetes CLI to run the Vault CLI `raft join` command to join
   additional nodes to the Vault cluster. For example, to add the Vault server
   on `vault-1`:

   ```shell-session
   $ kubectl exec vault-1 -- \
      vault operator raft join http://vault-0.vault-internal:8200
   ```

1. New nodes join the cluster sealed. Repeate the unseal process for each new
   node using `vault operator unseal`. For example, to unseal the server on
   `vault-1`:

   ```shell-session
   $ kubectl exec vault-1 -- \
      vault operator unseal $VAULT_UNSEAL_KEY
   ```

<Warning title="Revoke root tokens after setup">

   [Root tokens](/vault/docs/concepts/tokens#root-tokens) let users perform any
   operation on any path. We strongly recommend only using privileged tokens for
   the initial setup of a cluster. As part of the setup, you should configure
   at least one alternative authentication method and a basic access policy.
   Once you verify the alternative authentication method works, we recommend
   revoking the root token.

</Warning>


## Step 6: Test your cluster deployment 

You can test your deployment works correctly by enabling the
[`kv` plugin](/vault/docs/secrets/kv/kv-v2) and setting a test secret.

1. Use the Kubernetes CLI to start an interactive shell session on the first
   pod (`vault-0`):

   ```shell-session
   $ kubectl exec --stdin=true --tty=true vault-0 -- /bin/sh
   / $
   ```

1. Use the Vault CLI in your interactive session to enable the `kv` plugin at
   the path `creds`:

   ```shell-session
   $ vault secrets enable  \
      -path creds          \
      kv-v2
   ```

1. Use the Vault CLI in your interactive session to save a username and
   password at the path `creds/devapp`:

   ```shell-session
   $ vault kv put    \
      -mount creds   \
      devapp         \
      username='giraffe' password='salsa'
   ```

1. Use the Vault CLI in your interactive session to verify the secret saved
   correctly at `creds/devapp`:

   ```shell-session
   $ vault kv get -mount creds devapp
   ```


## Step 7: Create a Kubernetes service account for clients

Create a Kubernetes service account for clients so you can link the service
account to a Vault policy for authentication.

1. Create a Kubernetes service account with a unique name. For example, to
   create a service account called `internal-app`:

   ```shell-session
   $ kubectl create sa internal-app
   ```

1. Create a pod definition file for client applications. For example, to create
   a `devwebapp.yaml` file for a test application called `devwebapp` that runs
   with the `internal-app` Kubernetes service account:

   ```shell-session
   $ cat > devwebapp.yaml <<EOF
   ---
   apiVersion: v1
   kind: Pod
   metadata:
      name: devwebapp
      labels:
         app: devwebapp
      annotations:
         vault.hashicorp.com/agent-inject: "true"
         vault.hashicorp.com/role: "devweb-app"
         vault.hashicorp.com/agent-inject-secret-credentials.txt: "secret/data/devwebapp/config"
   spec:
   serviceAccountName: internal-app
   containers:
      - name: devwebapp
         image: caddy
   EOF
   ```

1. Create the client application pod. For example, to create a pod for the
   `devwebapp` test app:

   ```shell-session
   $ kubectl apply --filename devwebapp.yaml
   ```

1. Wait until your client pod reports that it is running and ready (`2/2`).


## Step 8: Enable Kubernetes authentication

Vault provides a [Kubernetes authentication](/vault/docs/auth/kubernetes) method
that lets clients authenticate with Kubernetes `ServiceAccount` tokens. With
Kubernetes authentication, Vault accepts service tokens from clients within
the Kubernetes cluster and verifies the service account token by querying a
token review Kubernetes endpoint.


1. If you closed the previous interactive shell session, use the Kubernetes CLI
   to start a new session on the first pod (`vault-0`):

   ```shell-session
   $ kubectl exec --stdin=true --tty=true vault-0 -- /bin/sh
   / $
   ```

1. Use the Vault CLI in your interactive session to enable the Kubernetes
   authentication plugin on the default path:

   ```shell-session
   $ vault auth enable kubernetes
   ```

1. Use the Vault CLI in your interactive session to configure the `kubernetes/`
   plugin to use the Kubernetes API to validate `ServiceAccount` tokens using
   the identity of the pod:

   ```shell-session
   $ vault write auth/kubernetes/config \
      kubernetes_host="https://${KUBERNETES_PORT_443_TCP_ADDR}:443"
   ```

1. Use the Vault CLI in your interactive session to write out a policy that lets
   clients read any required secrets. For example, to create a policy called
   `devwebapp` that lets clients read credentials from the `kv` path
   `creds/devapp`:

   ```shell-session
   $ vault policy write devwebapp - <<EOF
   path "creds/data/devapp" {
   capabilities = ["read"]
   }
   EOF
   ```

1. Use the Vault CLI in your interactive session to create a cooresponding
   Kubernetes authentication role that uses the new policy. For example, to
   create an authentication role called `devweb-app` that uses the `devwebapp` policy:

   ```shell-session
   $ vault write auth/kubernetes/role/devweb-app   \
         bound_service_account_names=internal-app  \
         bound_service_account_namespaces=default  \
         policies=devwebapp                        \
         ttl=24h
   ```

The authentication role connects the Kubernetes service account named in
`bound_service_account_names` to the Vault policy named in `policies`.



## Next steps

By default, application containers in the client pod are not aware of the Vault
cluster. You can use the Vault Injector service to read
[annotations](/vault/docs/platform/k8s/injector#annotations), find the
associated secret path in Vault, and mount a text file within the pod with the
secret information.

<Tip title="Format data with templates">

   Apply a
   [template](/vault/tutorials/kubernetes/kubernetes-sidecar#apply-a-template-to-the-injected-secrets)
   to the secret file to ensure the data meets the needs of your application.

</Tip>


## Additional resources

<Tabs>

<Tab heading="Guides" group="guides">

- [Vault Agent Injector](/vault/docs/deploy/kubernetes/injector)
- [Key/Vault plugin guides and cookbook](/vault/docs/secrets/kv/kv-v2)

</Tab>

<Tab heading="Tutorials" group="tutorial">

- [Using the versioned Key/Value secrets engine](/vault/tutorials/secrets-management/versioned-kv).
- [Use annotations to inject Secrets into Kubernetes Pods with Vault Agent Injector](/vault/tutorials/kubernetes/kubernetes-sidecar) tutorial.

</Tab>

<Tab heading="References" group="references">

- [`vault operator` commands](/vault/docs/commands/operator)
- [`/sys/storage/raft` endpoints](/vault/api-docs/system/storage/raft)

</Tab>

</Tabs>

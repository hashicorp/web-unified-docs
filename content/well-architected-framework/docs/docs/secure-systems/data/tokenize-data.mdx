---
page_title: Tokenize data
description: Replace sensitive data like credit card numbers with secure tokens using Vault's Transform engine to reduce breach risk and simplify compliance.
---

# Tokenize data

Tokenization replaces sensitive data with non-sensitive tokens that have no exploitable value if exposed. After [classifying your data](/well-architected-framework/secure-systems/data/classify-data) and implementing [encryption for data at rest](/well-architected-framework/secure-systems/data/protect-data-at-rest) and [in transit](/well-architected-framework/secure-systems/data/protect-data-in-transit), use tokenization for highly sensitive restricted data like credit card numbers, social security numbers, and banking credentials.

## Why tokenize data

**Prevent data exposure from token leaks:** Tokens contain no exploitable information. Unlike encrypted data that reveals sensitive information if encryption keys are compromised, tokens cannot be reversed without access to the tokenization system, limiting damage from security breaches.

**Simplify compliance requirements:** Payment Card Industry Data Security Standard (PCI-DSS) and similar regulations require extensive security controls for systems that store, process, or transmit sensitive data. Tokenization removes sensitive data from your systems, reducing the scope of compliance audits and associated security requirements.

**Maintain data format compatibility:** Systems often require specific data formats like 16-digit credit card numbers. Format-preserving tokenization generates tokens matching the original data pattern, enabling legacy system compatibility without code changes while protecting the underlying sensitive information.

## Tokenize data with Vault

Vault's Transform secrets engine tokenizes highly sensitive data by replacing it with algorithmically unrelated values. The tokenization system stores original values securely while applications work with tokens, preventing sensitive data exposure even if application databases are compromised.

```hcl
# Configure Vault Transform secrets engine for credit card tokenization
resource "vault_mount" "transform" {
  path = "transform"
  type = "transform"
}

resource "vault_transform_role" "payments" {
  path           = vault_mount.transform.path
  name           = "payments"
  transformations = ["card-number"]
}

resource "vault_transform_transformation" "card_number" {
  path     = vault_mount.transform.path
  name     = "card-number"
  type     = "fpe"
  template = "builtin/creditcardnumber"
  
  tweak_source      = "internal"
  allowed_roles     = ["payments"]
}

# Application tokenizes credit card before storage
data "vault_transform_encode" "customer_card" {
  path      = "${vault_mount.transform.path}/encode/${vault_transform_role.payments.name}"
  value     = "4111-1111-1111-1111"
  transformation = "card-number"
}
```

The Transform engine configuration creates a tokenization role for payment processing. When an application receives a credit card number, Vault tokenizes the value before storage. The token maintains the credit card format (16 digits) for system compatibility while protecting the actual number. Only applications with proper Vault authentication and authorization can detokenize values to retrieve original credit card numbers.

For data requiring encryption without format preservation, use [Vault's Transit secrets engine](/well-architected-framework/secure-systems/data/protect-data-in-transit) instead. Transit provides encryption as a service for data in transit without maintaining the original data format.

HashiCorp resources:

Data security documentation:

- [Classify data based on sensitivity levels](/well-architected-framework/secure-systems/data/classify-data) to organize information by access requirements
- [Protect sensitive data throughout its lifecycle](/well-architected-framework/secure-systems/data/protect-sensitive-data) from creation to deletion
- [Encrypt data at rest with Vault's security barrier](/well-architected-framework/secure-systems/data/protect-data-at-rest) to protect stored information
- [Encrypt data in transit using Vault and Consul](/well-architected-framework/secure-systems/data/protect-data-in-transit) to secure network communication

Vault Transform secrets engine:

- Read the [Vault Transform secrets engine documentation](/vault/docs/secrets/transform) for tokenization concepts
- Learn how to [tokenize sensitive data with Vault's Transform engine](/vault/tutorials/adp/tokenization) for PCI-DSS compliance

## Next steps

In this section of how to Secure data, you learned how to tokenize highly sensitive data using Vault's Transform secrets engine with format-preserving encryption. Tokenization completes your data protection strategy by replacing the most sensitive values with secure tokens that cannot be reversed without proper authorization. Tokenize data is part of the [Secure systems pillar](/well-architected-framework/secure-systems).

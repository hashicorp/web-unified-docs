---
page_title: Automate infrastructure and application deployments
description: Automate application and infrastructure deployments using infrastructure as code and container orchestration. Reduce deployment failures, enable rapid rollbacks, and eliminate configuration drift.
---

# Automate infrastructure and application deployments

Deployment automation eliminates manual errors and accelerates release cycles. Manual deployment processes create inconsistent environments, increase deployment failures, and slow down release cycles. Automate your deployments to reduce these risks and achieve predictable, repeatable processes for both infrastructure and applications.

Use infrastructure as code to provision infrastructure and deploy applications to container orchestrators or virtual machines with immutable infrastructure patterns.

## Why automate deployments

Automating deployments addresses the following operational and security challenges:

- **Reduce deployment inconsistencies:** When you automate deployments, you reduce human error and ensure that you configure every environment identically. Manual deployments can lead to configuration drift, where environments diverge over time. Automation implements consistency across development, staging, and production.

- **Reduce deployment time and risk:** Automated deployments are faster and less error-prone than manual processes. Automation enables frequent, small deployments. Manual deployments often involve multiple steps that increase the chance of mistakes and downtime.

- **Enable rapid rollback:** Automated deployments track all changes in version control, allowing you to rollback to previous states. If you manually deploy, you may not have a clear record of what changed, making it difficult to revert changes.
**Improve audit and compliance:** Manual processes lack detailed audit trails. Automation creates logs of who deployed what and when, meeting compliance requirements and simplifying troubleshooting.

When you automate deployments, you gain the following benefits:

- **Use infrastructure as code:** Define all infrastructure in version-controlled configuration files, enabling peer review, change tracking, and rollback capabilities. [Infrastructure as code](/well-architected-framework/define-and-automate-processes/define/as-code/infrastructure) reduces configuration errors and accelerates infrastructure provisioning.

- **Adopt immutable infrastructure:** Build images with your application pre-installed rather than configuring after deployment, increasing consistency between environments and simplifying troubleshooting. [Immutable infrastructure](/well-architected-framework/define-and-automate-processes/define/immutable-infrastructure) eliminates configuration drift and reduces deployment failures.

- **Promote through environments:** Validate automation in non-production before promoting to production, catching issues early and reducing production incidents. Start with a [development environment](/well-architected-framework/define-and-automate-processes/define/development-environment), progress to staging, then deploy to production with confidence.

- **Implement progressive deployments:** Deploy changes gradually with [zero-downtime strategies](/well-architected-framework/define-and-automate-processes/deploy/zero-downtime-deployments) like blue-green or canary deployments, minimizing risk and enabling quick rollbacks when issues occur.

## Automate infrastructure with Terraform

This section explains how to use Terraform and HCP Terraform to provision and manage infrastructure with version-controlled configuration.

Use Terraform to provision and manage your application infrastructure in a predictable, repeatable way. Terraform has thousands of providers, letting you deploy to any cloud provider or platform that has an API.

Use open source Terraform when you have a small team, can manage state files locally or in cloud storage, and want full control over execution environments. Use HCP Terraform when you have multiple team members making infrastructure changes, need policy enforcement, or want managed runners. HCP Terraform manages Terraform runs in a consistent and reliable environment, securely stores your state files, and enables team collaboration. HCP Terraform includes the following key features:

- Connect to your VCS provider for infrastructure development workflows
- Store modules in a private registry for code reuse
- Run tasks to integrate third-party services during deployment
- Granular access controls for team permissions
- Policy enforcement with Sentinel for configuration guardrails

The following is an example of a Terraform configuration that provisions infrastructure:

```hcl
terraform {
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
  }

  backend "s3" {
    bucket = "my-terraform-state"
    key    = "prod/terraform.tfstate"
    region = "us-west-2"
  }
}

provider "aws" {
  region = "us-west-2"
}

resource "aws_instance" "app" {
  ami           = "ami-12345678"  # AMI built with Packer
  instance_type = "t3.micro"

  tags = {
    Name        = "application-server"
    Environment = "production"
  }
}
```

This configuration configures the AWS provider, enables remote state storage in S3, and provisions an EC2 instance using an AMI built with Packer. The remote backend allows your team to share the same state file, decreasing the chances of conflicts when multiple people make infrastructure changes.

To learn more about Terraform configuration syntax and how to apply this configuration, visit the [Terraform getting started tutorials](/terraform/tutorials/aws-get-started).

## Automate application deployment

This section explains how to deploy packaged applications using container orchestrators or virtual machines with immutable infrastructure patterns.

Your application deployment strategy depends on your workload characteristics and operational requirements. After [packaging your application](/well-architected-framework/define-and-automate-processes/automate/packaging) into container or machine images, deploy these immutable artifacts using Terraform or a container orchestrator.

The deployment workflow follows these steps:

1. **Build images:** First, use Packer to create container images or machine images with your application pre-installed.
1. **Store artifacts:** Next, push container images to a registry (Docker Hub, ECR, ACR, GCR) or store machine images in your cloud provider (AMIs, Azure Images, GCE Images).
1. **Deploy:** Then, reference the stored images in your Terraform or container orchestrator configuration.
1. **Manage lifecycle:** Finally, use Terraform or your container orchestrator to update deployments when new image versions are available.

### Kubernetes deployment

Kubernetes automates deployment and scaling of containerized workloads with extensive ecosystem support. Use Kubernetes when you need advanced networking features, widespread third-party integrations, or multi-cloud container deployments. The Terraform Kubernetes provider lets you deploy and manage workloads through the Kubernetes API. Deploy Helm packages with the Helm Terraform provider.

Before deploying applications to Kubernetes with Terraform, you need a running Kubernetes cluster and kubectl configured to access it. The following example assumes your cluster is configured and you have pushed a container image to a registry. This Terraform configuration deploys a containerized application to Kubernetes:

```hcl
resource "kubernetes_deployment" "app" {
  metadata {
    name = "myapp"
    labels = {
      app = "myapp"
    }
  }

  spec {
    replicas = 3

    selector {
      match_labels = {
        app = "myapp"
      }
    }

    template {
      metadata {
        labels = {
          app = "myapp"
        }
      }

      spec {
        container {
          name  = "myapp"
          image = "myregistry/myapp:v1.0.0"  # Container image built with Packer

          port {
            container_port = 8080
          }

          resources {
            requests = {
              cpu    = "100m"
              memory = "128Mi"
            }
            limits = {
              cpu    = "500m"
              memory = "512Mi"
            }
          }
        }
      }
    }
  }
}

resource "kubernetes_service" "app" {
  metadata {
    name = "myapp-service"
  }

  spec {
    selector = {
      app = kubernetes_deployment.app.metadata[0].labels.app
    }

    port {
      port        = 80
      target_port = 8080
    }

    type = "LoadBalancer"
  }
}
```

This configuration deploys three replicas of a containerized application to Kubernetes, defines resource requests and limits for predictable performance, and creates a LoadBalancer service to expose the application externally.

### Nomad deployment

Nomad orchestrates containers, standalone binaries, and batch jobs with simplified operations and better resource efficiency. Use Nomad when you need to manage diverse workload types, prefer streamlined operations, or require higher density and performance. Use the Terraform Nomad provider to manage workloads as code, or use Nomad Pack for templating and package management.

Before deploying applications to Nomad with Terraform, you need a running Nomad cluster. The following example assumes your cluster is configured and you have pushed a container image to a registry. This Terraform configuration deploys a containerized application to Nomad:

```hcl
resource "nomad_job" "app" {
  jobspec = <<EOT
job "myapp" {
  datacenters = ["dc1"]
  type        = "service"

  group "app" {
    count = 3

    task "myapp" {
      driver = "docker"

      config {
        image = "myregistry/myapp:v1.0.0"  # Container image built with Packer
        ports = ["http"]
      }

      resources {
        cpu    = 500
        memory = 512
      }

      service {
        name = "myapp"
        port = "http"

        check {
          type     = "http"
          path     = "/health"
          interval = "10s"
          timeout  = "2s"
        }
      }
    }

    network {
      port "http" {
        static = 8080
      }
    }
  }
}
EOT
}
```

This configuration deploys three instances of a containerized application to Nomad, defines resource allocations, and configures health checks to ensure the application is running correctly before routing traffic to it.

HashiCorp resources:
- Learn how to use [Terraform to deploy your tools](/well-architected-framework/define-and-automate-processes/define/as-code) such as container orchestration, database infrastructure, version control systems, and more.
- Reference the [Terraform documentation](/terraform/docs).
- Try the [Terraform tutorials](/terraform/tutorials).
- View the thousands of [Terraform providers](https://registry.terraform.io/browse/providers)
- [Use version control](/well-architected-framework/define-and-automate-processes/define/version-control) to store infrastructure configurations.
- [Create reusable Terraform modules](/well-architected-framework/define-and-automate-processes/define/modules) to standardize infrastructure deployments.
- Implement a [GitOps workflow](/well-architected-framework/define-and-automate-processes/process-automation/gitops).

To learn how to deploy applications to Kubernetes with Terraform:
- Try the [Deploy Federated Multi-Cloud Kubernetes Clusters](/terraform/tutorials/kubernetes/multicloud-kubernetes) tutorial.
- Read the [Terraform Kubernetes provider documentation](https://registry.terraform.io/providers/hashicorp/kubernetes/latest/docs).
- Learn how to [Schedule deployments with Terraform](/terraform/tutorials/kubernetes/kubernetes-operator-v2).
- Deploy Helm packages with the [Helm Terraform provider](https://registry.terraform.io/providers/hashicorp/helm/latest/docs)

To learn how to deploy applications to Nomad with Terraform:
- Try the [Deploy a Nomad cluster on AWS](/nomad/tutorials/get-started/get-started-install) tutorial.
- Read the [Terraform Nomad provider documentation](https://registry.terraform.io/providers/hashicorp/nomad/latest/docs).
- Learn about [Nomad job specifications](/nomad/docs/job-specification).
- Use [Nomad Pack](https://github.com/hashicorp/nomad-pack) for templating and package management.

## Next steps

In this section of Automate your workflows, you learned how to automate deployments for both infrastructure and applications. Automated deployments are part of the [Define and automate processes pillar](/well-architected-framework/define-and-automate-processes).

Visit the following documents to learn more about the automation workflow:

- Implement small, frequent infrastructure deployments with [atomic deployments](/well-architected-framework/define-and-automate-processes/deploy/atomic-deployments).
- Implement [zero-downtime deployments](/well-architected-framework/define-and-automate-processes/deploy/zero-downtime-deployments).
- [Create CI/CD pipelines](/well-architected-framework/define-and-automate-processes/automate/cicd) to automate infrastructure and application deployments.
- Use infrastructure as code to [Define CI/CD infrastructure](/well-architected-framework/define-and-automate-processes/define/as-code/cicd).

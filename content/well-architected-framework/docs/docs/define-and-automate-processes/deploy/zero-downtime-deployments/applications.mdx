---
page_title: Deploy applications with zero downtime
description: Deploy applications without downtime using blue/green, canary, and rolling strategies. Use load balancers and orchestrators for traffic shifting.
---

# Deploy applications with zero downtime

Application deployments cause downtime, service disruptions, and deployment risk when updates deploy directly to production. Traditional deployment approaches take applications offline during updates, causing revenue loss and poor user experience. Deploy applications using zero-downtime strategies - blue/green, canary, rolling, or combinations - to maintain availability during updates, reduce deployment risk, and enable safe rollback.

Your deployment strategy depends on your infrastructure (virtual machines or containers), orchestration tools (Nomad, Kubernetes), and application criticality. Use load balancers and orchestrators to gradually shift traffic, test changes with production load, and rollback instantly when issues occur.

## Why deploy applications with zero downtime

Deploying applications with zero-downtime strategies addresses the following operational challenges:

- **Eliminate service disruptions and revenue loss:** Application downtime during deployments causes lost revenue, frustrated users, and damaged reputation. Zero-downtime deployments maintain service availability throughout updates, ensuring users experience no interruptions.

- **Reduce deployment risk with gradual rollouts:** Deploying application changes to all users simultaneously creates high risk - if issues occur, all users are affected. Canary and rolling deployments gradually shift traffic, limiting the blast radius and allowing you to catch issues before full rollout.

- **Enable instant rollback capabilities:** When application updates cause bugs or performance issues, traditional deployments require time-consuming rollback procedures. Blue/green deployments maintain the previous version running, allowing instant traffic switching back to the working version.

- **Test changes with production traffic:** Staging environments don't replicate production load patterns and data. Canary deployments let you test changes with real production traffic on a small user subset, validating performance and functionality before full deployment.

## Load balancers and proxies

Load balancers and reverse proxies can manage your application by directing traffic between your blue and green environments. They can then direct a subset of users for canary deployments and testing and control traffic for rolling deployments.

Load balancers and proxies route traffic between application environments during updates. They support blue-green deployments and canary releases, allowing you to gradually shift users to new versions while maintaining the ability to roll back if issues occur. By continuously monitoring application health and automatically routing around failed instances, they increase service availability throughout the deployment process.

Regardless of your cloud provider, you can use Terraform to manage the deployment and control of load balancers and proxies. Using Terraform for IaC allows you to version control your load balancer configurations alongside your application code, ensuring that changes are tracked, reviewed, and rolled back if needed. You can define target groups, health check parameters, routing rules, and SSL certificates declaratively, then apply these configurations automatically as part of your CI/CD pipeline.

The following example shows Terraform configuration for canary deployment using AWS Application Load Balancer with weighted target groups:

```hcl
# Create target group for stable (blue) version
resource "aws_lb_target_group" "blue" {
  name     = "app-blue"
  port     = 8080
  protocol = "HTTP"
  vpc_id   = var.vpc_id

  health_check {
    enabled             = true
    healthy_threshold   = 2
    interval            = 30
    path                = "/health"
    timeout             = 5
  }
}

# Create target group for new (green) version
resource "aws_lb_target_group" "green" {
  name     = "app-green"
  port     = 8080
  protocol = "HTTP"
  vpc_id   = var.vpc_id

  health_check {
    enabled             = true
    healthy_threshold   = 2
    interval            = 30
    path                = "/health"
    timeout             = 5
  }
}

# Configure listener with weighted traffic distribution
resource "aws_lb_listener" "app" {
  load_balancer_arn = aws_lb.main.arn
  port              = "80"
  protocol          = "HTTP"

  default_action {
    type = "forward"

    forward {
      target_group {
        arn    = aws_lb_target_group.blue.arn
        weight = 90  # 90% of traffic to stable version
      }

      target_group {
        arn    = aws_lb_target_group.green.arn
        weight = 10  # 10% of traffic to canary version
      }

      stickiness {
        enabled  = false
        duration = 600
      }
    }
  }
}
```

This configuration creates two target groups and distributes traffic with a 90/10 split for canary testing. To gradually shift traffic, update the weight values (for example, 50/50, then 0/100) and run `terraform apply`. The load balancer immediately adjusts traffic distribution without downtime.

To learn how to implement canary deployments with AWS Application Load Balancers, follow the [blue-green and canary deployments tutorial](/terraform/tutorials/aws/blue-green-canary-tests-deployments).

HashiCorp resources:
- [Use Application Load Balancers for blue-green and canary deployments](/terraform/tutorials/aws/blue-green-canary-tests-deployments) - Complete AWS tutorial
- [AWS Load Balancer target group](/terraform/providers/aws/latest/docs/resources/lb_target_group) - Configure target groups
- [AWS Load Balancer listener](/terraform/providers/aws/latest/docs/resources/lb_listener) - Configure weighted traffic distribution

External resources:
- [AWS Fine-tuning blue/green deployments on application load balancer](https://aws.amazon.com/blogs/devops/blue-green-deployments-with-application-load-balancer/)
- [Using AWS Load Balancer Controller for blue/green deployment, canary deployment and A/B testing](https://aws.amazon.com/blogs/containers/using-aws-load-balancer-controller-for-blue-green-deployment-canary-deployment-and-a-b-testing/)
- [Azure Blue-Green deployments using Azure Traffic Manager](https://azure.microsoft.com/en-us/blog/blue-green-deployments-using-azure-traffic-manager/)
- [F5 Flexible Load Balancing for Blue/Green Deployments and Beyond](https://www.f5.com/resources/solution-guides/flexible-load-balancing-for-blue-green-deployments-and-beyond)

## Choose a deployment strategy

Select your deployment strategy based on application requirements, infrastructure constraints, and risk tolerance.

Use the following criteria to choose a deployment strategy:

**Use blue/green deployments when you need:**
- Instant rollback capability for critical applications
- Complete validation before switching traffic
- Ability to maintain two full environments simultaneously
- Predictable cutover timing

**Use canary deployments when you need:**
- Risk reduction for high-impact changes
- Gradual validation with real production traffic
- Early detection of issues before full rollout
- Ability to test with a subset of users first

**Use rolling deployments when you need:**
- Resource efficiency with minimal overhead
- Gradual replacement without double infrastructure costs
- Continuous availability during updates
- Automated orchestration with Kubernetes or Nomad

Combine strategies for comprehensive safety. For example, use blue/green deployment with canary testing - deploy to green environment, route 10% traffic for canary validation, then switch all traffic if successful.

## Deploy applications on virtual machines

Blue/green and canary deployments work well for applications on virtual machines. Blue/green deployments limit downtime and reduce risk by maintaining two identical production environments - one live, one idle. You deploy to the idle environment, test thoroughly, then switch traffic over. If problems occur, rollback immediately by switching traffic back.

For high-impact applications, incorporate canary testing into your blue/green deployment strategy. This testing method validates your new version with production traffic before fully transitioning, ensuring stable user experience.

The following is an example of canary testing your green environment:

After the green environment is ready, the load balancer sends a small fraction of the traffic to the green environment (in this example, 10%).

![Canary test/deployment. All traffic is directed to the blue environment initially. When you perform a canary test, 10% of the traffic is directed to the green environment.](/img/well-architected-framework/blue-green-canary-tests-deployments/canary-deployment.png)

If the canary test succeeds without errors, you can incrementally direct traffic to the green environment (50/50 â€” split traffic) over time. In the end state, you redirect all traffic to the green environment. After verifying the new deployment, you can destroy the old blue environment. The green environment is now your current production service.

![Rolling deployment. After the initial canary test, traffic to the green environment is split evenly with the blue environment (50/50). Finally, all traffic is directed to the green environment.](/img/well-architected-framework/blue-green-canary-tests-deployments/rolling-deployment.png)

## Deploy containerized applications with orchestration tools

Containers support rolling, blue/green, and canary deployments through orchestration tools like Nomad and Kubernetes. Orchestrators automate the deployment process, manage health checks, and handle traffic routing during updates.

The following deployment strategies lower downtime risk:

- **Blue/green deployments:** Provide instant rollback capability by maintaining two identical environments and switching traffic between them, ensuring zero downtime but requiring double the resources.
- **Rolling deployments:** Gradually replace instances one by one, minimizing resource usage while maintaining availability, making them efficient for resource-constrained environments.
- **Canary deployments:** Mitigate risk by releasing to a small subset of users first, allowing you to validate changes and catch issues before full rollout.

### Rolling deployments with Nomad

Nomad supports rolling updates as a first-class feature. Use the `update` block to control how Nomad replaces old allocations with new ones during deployment.

The following example shows a Nomad job specification with rolling update configuration:

```hcl
job "web-app" {
  datacenters = ["dc1"]
  type        = "service"

  update {
    max_parallel      = 2          # Update 2 instances at a time
    health_check      = "checks"   # Wait for health checks to pass
    min_healthy_time  = "10s"      # Minimum time to be healthy
    healthy_deadline  = "5m"       # Maximum time to become healthy
    progress_deadline = "10m"      # Overall deployment timeout
    auto_revert       = true       # Automatically revert on failure
    canary            = 2          # Deploy 2 canary instances first
  }

  group "web" {
    count = 6  # Total 6 instances

    network {
      port "http" {
        to = 8080
      }
    }

    service {
      name = "web-app"
      port = "http"

      check {
        type     = "http"
        path     = "/health"
        interval = "10s"
        timeout  = "2s"
      }
    }

    task "app" {
      driver = "docker"

      config {
        image = "myregistry/myapp:1.0.0"
        ports = ["http"]
      }
    }
  }
}
```

This configuration deploys 6 instances with rolling updates. Nomad first deploys 2 canary instances, waits for health checks to pass for 10 seconds, then progressively updates 2 instances at a time. If any instance fails health checks, Nomad automatically reverts to the previous version. The `progress_deadline` ensures the entire deployment completes within 10 minutes or fails.

To learn how to implement rolling and canary deployments with Nomad, follow the [Nomad job updates tutorials](/nomad/tutorials/job-updates).

### Rolling deployments with Kubernetes

Kubernetes uses rolling updates by default. Kubernetes incrementally replaces current pods with new ones, scheduling new pods on nodes with available resources and waiting for them to become ready before removing old pods.

Both Nomad and Kubernetes support blue/green deployments. Before sending all traffic to your new deployment, use canary testing to validate the new version works correctly with production traffic.

HashiCorp resources:

- [Nomad blue/green and canary deployments](/nomad/tutorials/job-updates/job-blue-green-and-canary-deployments) - Complete tutorial on Nomad deployment strategies
- [Nomad rolling updates](/nomad/tutorials/job-updates/job-rolling-update) - Tutorial on rolling deployments
- [Nomad update block reference](/nomad/docs/job-specification/update) - Configure rolling upgrades and canary deployments
- [Nomad job updates tutorials](/nomad/tutorials/job-updates) - All Nomad deployment tutorials

External resources:

- [Kubernetes - Performing a rolling update](https://kubernetes.io/docs/tutorials/kubernetes-basics/update/update-intro/) - Kubernetes deployment guide

## Next steps

In this section of Zero-downtime deployments, you learned how to deploy application changes using blue/green, canary, and rolling strategies with load balancers and orchestrators. Zero-downtime deployments are part of the [Define and automate processes pillar](/well-architected-framework/define-and-automate-processes).

Refer to the following documents to learn more about deployment strategies:

- [Zero-downtime deployments overview](/well-architected-framework/define-and-automate-processes/deploy/zero-downtime-deployments) - Learn about different deployment strategies
- [Deploy blue/green infrastructure](/well-architected-framework/define-and-automate-processes/deploy/zero-downtime-deployments/infrastructure) - Blue/green for infrastructure changes
- [Traffic splitting with service mesh](/well-architected-framework/define-and-automate-processes/deploy/zero-downtime-deployments/service-mesh) - Advanced traffic management
- [Deploy atomic infrastructure](/well-architected-framework/define-and-automate-processes/deploy/atomic-deployments) - Reduce deployment risk with small changes
- [Package applications](/well-architected-framework/define-and-automate-processes/automate/packaging) - Create deployable artifacts with Packer
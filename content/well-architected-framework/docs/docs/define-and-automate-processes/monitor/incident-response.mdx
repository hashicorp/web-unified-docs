---
page_title: Automate incident response with runbooks and alerting integrations
description: Reduce mean time to recovery by automating incident response workflows. Use Terraform to configure alerting integrations and standardize runbook execution.
---

# Automate incident response with Terraform

Monitoring and alerting systems detect problems, but they do not solve them. When alerts fire at 3 AM, teams scramble to remember procedures, find documentation, and execute manual steps under pressure. Terraform lets you automate incident response by configuring alerting integrations, defining escalation policies, and standardizing runbook execution so your team responds consistently and quickly to every incident.

Automated incident response reduces Mean Time to Recovery (MTTR) by eliminating the delay between alert and action. When response procedures execute automatically or with minimal manual intervention, you restore services faster and reduce the impact of outages on your users and business.

## Why automate incident response

Automating your incident response workflows addresses the following operational challenges:

- **Reduce mean time to recovery:** Manual incident response requires engineers to wake up, assess the situation, find documentation, and execute procedures. Automated response triggers immediately when alerts fire, reducing MTTR from hours to minutes for common incident types.
- **Ensure consistent response procedures:** Different engineers respond to incidents differently, leading to inconsistent outcomes and missed steps. Automated runbooks execute the same procedures every time, ensuring consistent response quality regardless of who is on call.
- **Capture incident context automatically:** Engineers troubleshooting incidents manually often forget to document their actions and findings. Automated response systems capture context, timeline, and actions automatically, improving post-incident reviews and future incident handling.
- **Scale incident handling capacity:** As infrastructure grows, incident volume increases faster than team capacity. Automated response handles routine incidents without human intervention, freeing engineers to focus on complex problems that require human judgment.

## How automated incident response works

Automated incident response connects your monitoring systems to response workflows through alerting integrations, escalation policies, and runbook automation.

The incident response workflow consists of the following key components:

- **Alert routing:** Monitoring systems send alerts to incident management platforms based on severity, service, and time of day
- **Escalation policies:** Define who gets notified, when to escalate, and how to reach on-call engineers
- **Automated runbooks:** Pre-defined procedures that execute automatically or with one-click approval
- **Incident tracking:** Centralized incident records with timeline, actions taken, and resolution status
- **Post-incident analysis:** Automated collection of metrics, logs, and actions for review

## Configure alerting integrations with Terraform

The following examples show how to configure alerting integrations that route monitoring alerts to your incident management platform.

<Tabs>
<Tab heading="PagerDuty" group="incident-platform">

```hcl
# Configure PagerDuty service and escalation policy
resource "pagerduty_escalation_policy" "platform_team" {
  name      = "Platform Team Escalation"
  num_loops = 2

  rule {
    escalation_delay_in_minutes = 15
    target {
      type = "schedule_reference"
      id   = pagerduty_schedule.platform_oncall.id
    }
  }

  rule {
    escalation_delay_in_minutes = 30
    target {
      type = "user_reference"
      id   = pagerduty_user.platform_lead.id
    }
  }
}

resource "pagerduty_service" "production_infrastructure" {
  name              = "Production Infrastructure"
  escalation_policy = pagerduty_escalation_policy.platform_team.id
  alert_creation    = "create_alerts_and_incidents"

  incident_urgency_rule {
    type    = "constant"
    urgency = "high"
  }

  auto_resolve_timeout    = 14400
  acknowledgement_timeout = 1800
}

# Create integration key for monitoring systems
resource "pagerduty_service_integration" "datadog" {
  name    = "Datadog Integration"
  service = pagerduty_service.production_infrastructure.id
  vendor  = data.pagerduty_vendor.datadog.id
}

# Configure Datadog to send alerts to PagerDuty
resource "datadog_integration_pagerduty_service_object" "production" {
  service_name = pagerduty_service.production_infrastructure.name
  service_key  = pagerduty_service_integration.datadog.integration_key
}
```

The configuration creates a PagerDuty escalation policy with two escalation levels, a service for production infrastructure alerts, and integrates with Datadog to automatically route alerts to the on-call team.

</Tab>
<Tab heading="Opsgenie" group="incident-platform">

```hcl
# Configure Opsgenie team and escalation
resource "opsgenie_team" "platform" {
  name        = "Platform Team"
  description = "Infrastructure and platform engineering"
}

resource "opsgenie_escalation" "platform_escalation" {
  name      = "Platform Team Escalation"
  owner_team_id = opsgenie_team.platform.id

  rules {
    condition   = "if-not-acked"
    notify_type = "default"
    delay       = 15

    recipient {
      type = "schedule"
      id   = opsgenie_schedule.platform_oncall.id
    }
  }

  rules {
    condition   = "if-not-acked"
    notify_type = "default"
    delay       = 30

    recipient {
      type = "user"
      id   = opsgenie_user.platform_lead.id
    }
  }
}

# Create API integration for monitoring systems
resource "opsgenie_api_integration" "datadog" {
  name = "Datadog Integration"
  type = "Datadog"

  owner_team_id = opsgenie_team.platform.id

  responders {
    type = "escalation"
    id   = opsgenie_escalation.platform_escalation.id
  }
}
```

The configuration creates an Opsgenie team with an escalation policy and a Datadog integration that routes alerts through the defined escalation rules.

</Tab>
<Tab heading="AWS" group="incident-platform">

```hcl
# Configure SNS topic for incident notifications
resource "aws_sns_topic" "incident_alerts" {
  name = "production-incident-alerts"
}

# Subscribe on-call team to alerts
resource "aws_sns_topic_subscription" "oncall_email" {
  topic_arn = aws_sns_topic.incident_alerts.arn
  protocol  = "email"
  endpoint  = "oncall@example.com"
}

# Configure CloudWatch alarm to trigger incidents
resource "aws_cloudwatch_metric_alarm" "high_error_rate" {
  alarm_name          = "production-high-error-rate"
  comparison_operator = "GreaterThanThreshold"
  evaluation_periods  = 2
  metric_name         = "5XXError"
  namespace           = "AWS/ApplicationELB"
  period              = 60
  statistic           = "Sum"
  threshold           = 100
  alarm_description   = "High error rate detected in production"

  alarm_actions = [aws_sns_topic.incident_alerts.arn]
  ok_actions    = [aws_sns_topic.incident_alerts.arn]

  dimensions = {
    LoadBalancer = aws_lb.production.arn_suffix
  }
}

# Trigger automated runbook on alarm
resource "aws_cloudwatch_metric_alarm" "trigger_runbook" {
  alarm_name          = "auto-remediation-trigger"
  comparison_operator = "GreaterThanThreshold"
  evaluation_periods  = 1
  metric_name         = "5XXError"
  namespace           = "AWS/ApplicationELB"
  period              = 60
  statistic           = "Sum"
  threshold           = 500
  alarm_description   = "Critical error rate - trigger automated remediation"

  alarm_actions = [aws_ssm_document.restart_service.arn]
}
```

The configuration creates SNS topics for alert notifications, CloudWatch alarms for error rate monitoring, and triggers automated remediation runbooks when critical thresholds are exceeded.

</Tab>
</Tabs>

Each configuration connects monitoring systems to incident management platforms with defined escalation policies. The alerts route to on-call engineers with automatic escalation if incidents are not acknowledged within defined timeframes.

## Define automated runbooks

Automated runbooks execute pre-defined response procedures when incidents occur. The following example shows an AWS Systems Manager runbook that automatically restarts unhealthy services.

```hcl
resource "aws_ssm_document" "restart_unhealthy_service" {
  name          = "RestartUnhealthyService"
  document_type = "Automation"

  content = jsonencode({
    schemaVersion = "0.3"
    description   = "Restart unhealthy ECS service tasks"
    assumeRole    = aws_iam_role.automation_role.arn

    parameters = {
      ClusterName = {
        type        = "String"
        description = "ECS cluster name"
      }
      ServiceName = {
        type        = "String"
        description = "ECS service name"
      }
    }

    mainSteps = [
      {
        name   = "GetCurrentTaskCount"
        action = "aws:executeAwsApi"
        inputs = {
          Service = "ecs"
          Api     = "DescribeServices"
          cluster = "{{ ClusterName }}"
          services = ["{{ ServiceName }}"]
        }
        outputs = [
          {
            Name     = "DesiredCount"
            Selector = "$.services[0].desiredCount"
            Type     = "Integer"
          }
        ]
      },
      {
        name   = "ForceNewDeployment"
        action = "aws:executeAwsApi"
        inputs = {
          Service            = "ecs"
          Api                = "UpdateService"
          cluster            = "{{ ClusterName }}"
          service            = "{{ ServiceName }}"
          forceNewDeployment = true
        }
      },
      {
        name   = "WaitForStableService"
        action = "aws:waitForAwsResourceProperty"
        inputs = {
          Service      = "ecs"
          Api          = "DescribeServices"
          cluster      = "{{ ClusterName }}"
          services     = ["{{ ServiceName }}"]
          PropertySelector = "$.services[0].deployments[0].runningCount"
          DesiredValues    = ["{{ GetCurrentTaskCount.DesiredCount }}"]
        }
        timeoutSeconds = 600
      },
      {
        name   = "RecordIncidentResolution"
        action = "aws:executeAwsApi"
        inputs = {
          Service = "cloudwatch"
          Api     = "PutMetricData"
          Namespace  = "IncidentResponse"
          MetricData = [
            {
              MetricName = "AutomatedRemediationSuccess"
              Value      = 1
              Unit       = "Count"
              Dimensions = [
                {
                  Name  = "ServiceName"
                  Value = "{{ ServiceName }}"
                }
              ]
            }
          ]
        }
      }
    ]
  })
}
```

The runbook captures the current task count, forces a new deployment to restart unhealthy tasks, waits for the service to stabilize, and records metrics for tracking automated remediation success rates.

## Respond to incidents effectively

When automated response does not fully resolve an incident, engineers must intervene. Complete the following steps to handle incidents that require human judgment:

1. **Acknowledge the incident:** Claim ownership in your incident management platform to stop escalation and let others know someone is responding.
1. **Assess severity and impact:** Determine which services are affected, how many users are impacted, and whether the incident is ongoing or resolved.
1. **Execute appropriate runbook:** Follow the documented runbook for the incident type, using automation where available and manual steps where necessary.
1. **Communicate status updates:** Post regular updates to incident channels so stakeholders know what is happening and when to expect resolution.
1. **Document resolution and root cause:** Record what fixed the incident and what caused it so post-incident review can identify prevention measures.

HashiCorp resources:

- Learn Terraform with the [Terraform tutorials](/terraform/tutorials) and read the [Terraform documentation](/terraform/docs)
- Configure [monitoring dashboards and alerts](/well-architected-framework/define-and-automate-processes/monitor/dashboards-alerts) for comprehensive observability
- Implement [CI/CD pipelines](/well-architected-framework/define-and-automate-processes/automate/cicd) that include automated testing and rollback
- Explore [pagerduty_service](https://registry.terraform.io/providers/PagerDuty/pagerduty/latest/docs/resources/service) for PagerDuty service configuration
- Explore [opsgenie_escalation](https://registry.terraform.io/providers/opsgenie/opsgenie/latest/docs/resources/escalation) for Opsgenie escalation policies
- Explore [aws_ssm_document](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/ssm_document) for AWS Systems Manager automation runbooks

External resources:

- [PagerDuty incident response guide](https://response.pagerduty.com/) covers incident response best practices and procedures
- [AWS Systems Manager Automation](https://docs.aws.amazon.com/systems-manager/latest/userguide/systems-manager-automation.html) explains automated runbook execution
- [Google SRE workbook on incident response](https://sre.google/workbook/incident-response/) walks through incident management practices

## Next steps

In this section of Define and automate processes, you learned how to automate incident response with Terraform by configuring alerting integrations, defining escalation policies, and creating automated runbooks. Incident response automation is part of the [Define and automate processes pillar](/well-architected-framework/define-and-automate-processes).

Visit the following documents to continue building your operational automation:

- Set up [monitoring agents](/well-architected-framework/define-and-automate-processes/monitor/setup-monitoring-agents) to collect metrics that trigger alerts
- Implement [fully-automated deployments](/well-architected-framework/define-and-automate-processes/process-automation/fully-automated) for self-healing infrastructure

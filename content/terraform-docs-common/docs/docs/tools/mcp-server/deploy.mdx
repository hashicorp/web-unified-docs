---
page_title: Deploy the Terraform model context protocol (MCP) server 
description: |-
 Learn how to deploy the Terraform MCP server, which helps you write configuration using LLM responses sourced from the Terraform registry.
---

# Deploy the Terraform MCP server

The Terraform Model Context Protocol (MCP) server enables AI models to generate Terraform configuration using up-to-date information from the Terraform Registry. This page explains how to install, configure, and integrate the MCP server with your AI client.

@include 'beta.mdx'

## Overview

The Terraform MCP server is a specialized service that provides AI models with access to current Terraform provider documentation and module information. You can deploy the server to the following environments:

- **Local deployment**: Run the server on your workstation using `stdio` mode for direct communication through standard input/output
- **Remote deployment**: Run the server on a remote instance using `streamable-http` mode for network-based communication

### Installation methods

Choose from three installation options based on your environment and preferences:

| Method | Best for | Requirements |
|--------|----------|--------------|
| [Docker](#run-in-docker) | Most users, consistent environments | Docker Engine v20.10.21+ or Docker Desktop v4.14.0+. Refer to the [Docker documentation](https://docs.docker.com/desktop) for installation instructions. |
| [Compiled binary](#run-the-compiled-binary) | Lightweight deployments, specific OS needs | Compatible operating system |
| [Source installation](#install-from-source) | Development, customization | Go development environment |

## Run in Docker

Docker provides the most reliable and consistent way to run the Terraform MCP server across different environments.

1. Start Docker on your system.
1. Integrate with your AI client:

<Tabs>

<Tab heading="Visual Studio Code">

1. Verify [Visual Studio Code](https://code.visualstudio.com/docs) is installed.
1. Verify the [GitHub Copilot extension](https://code.visualstudio.com/docs/copilot/overview) is installed and chats are configured to `Agent` mode.
1. Verify MCP support enabled, refer to the [VS Code MCP documentation](https://code.visualstudio.com/docs/copilot/chat/mcp-servers) for more information.
1. To use the MCP server in all workspaces, add the following configuration to your user settings JSON file:

  ```json
  {
    "mcp": {
      "servers": {
        "terraform": {
          "command": "docker",
          "args": [
            "run",
            "-i",
            "--rm",
            "hashicorp/terraform-mcp-server"
          ]
        }
      }
    }
  }
  ```

  Alternatively, to use the server in a specific workspace, create an `mcp.json` file with the following configuration in your workspace's `.vscode` directory:

  ```json
  {
    "servers": {
      "terraform": {
        "command": "docker",
        "args": [
          "run",
          "-i",
          "--rm",
          "hashicorp/terraform-mcp-server"
        ]
      }
    }
  }
  ```

1. Verify the integration by opening the chat interface and selecting **Agent** from the mode settings.
1. Click the tools icon to verify that Terraform MCP server tools appear in the available tools list.

</Tab>
<Tab heading="Cursor">

1. Verify [Cursor](https://www.cursor.com) is installed.
1. Verify the MCP support configured, refer to [Cursor's MCP documentation](https://docs.cursor.com/context/model-context-protocol#configuring-mcp-servers) for more information.    
1. To use the MCP server in all workspaces, add the following configuration to your user settings JSON file:

  ```json
  {
    "mcp": {
      "servers": {
        "terraform": {
          "command": "docker",
          "args": [
            "run",
            "-i",
            "--rm",
            "hashicorp/terraform-mcp-server"
          ]
        }
      }
    }
  }
  ```

  Alternatively, to use the server in a specific workspace, create an `mcp.json` file with the following configuration in your workspace's `.vscode` directory:

  ```json
  {
    "servers": {
      "terraform": {
        "command": "docker",
        "args": [
          "run",
          "-i",
          "--rm",
          "hashicorp/terraform-mcp-server"
        ]
      }
    }
  }
  ```

1. Verify the installation by opening the chat pane and selecting **Chat Settings** from the ellipses menu.
1. Choose **Agent** from the **Default new chat mode** drop-down menu.
1. Select **MCP** from the **Cursor Settings** sidebar to verify that Terraform MCP server tools are enabled. Refer to the [tools reference](/terraform/docs/tools/mcp-server/reference#available-tools) for more information.
  
</Tab>
<Tab heading="Claude Desktop">

1. Verify [Claude Desktop](https://support.anthropic.com/en/articles/10065433-installing-claude-for-desktop) is installed.
1. Verify MCP support is configured, refer to [Claude Desktop's MCP documentation](https://modelcontextprotocol.io/quickstart/user) for more information.    
1. Create or edit the `mcp.json` file and add the following configuration:

  ```json
  {
    "mcpServers": {
      "servers": {
        "hcp-terraform": {
          "command": "docker",
          "args": [
            "run",
            "-i",
            "--rm",
            "hashicorp/terraform-mcp-server"
          ]
        }
      }
    }
  }
  ```

1. Verify the integration by opening the chat pane and clicking the **search and tools** slider icon.
1. Click **terraform-mcp-server** to verify that all tools are enabled and accessible. Refer to the [tools reference](/terraform/docs/tools/mcp-server/reference#available-tools) for more information.

</Tab>
<Tab heading="Amazon Q">

1. Verify [Amazon Q](https://docs.aws.amazon.com/amazonq/latest/qdeveloper-ug/command-line-installing.html) is installed.
1. Verify MCP support is configured, refer to [Amazon Q's MCP documentation](https://docs.aws.amazon.com/amazonq/latest/qdeveloper-ug/qdev-mcp.html) for more information.    
1. Create or edit the `mcp.json` file with the following configuration:

```json
{
  "mcpServers": {
    "servers": {
      "hcp-terraform": {
        "command": "docker",
        "args": [
          "run",
          "-i",
          "--rm",
          "hashicorp/terraform-mcp-server"
        ]
      }
    }
  }
}
```
  
</Tab>
</Tabs>

## Run the compiled binary

The compiled binary option provides a lightweight installation without Docker dependencies. This method is ideal when you want to minimize resource usage or work in environments with restricted container access.

1. Download the binary for your operating system and architecture, visit the [release library](https://releases.hashicorp.com/terraform-mcp-server).  
1. Add the following configuration to your client settings. Replace `/path/to/terraform-mcp-server` with the actual path to your downloaded binary.

  <CodeBlockConfig highlight="5">

  ```json
  {
    "mcp": {
      "servers": {
        "terraform": {
          "command": "/path/to/terraform-mcp-server",
          "args": ["stdio"]
        }
      }
    }
  }
  ```

  </CodeBlockConfig>

## Install from source

Installing from source gives you access to the latest features and allows for customization. This method requires a Go development environment.

1. Install the latest stable release.

  ```shell-session
  $ go install github.com/hashicorp/terraform-mcp-server/cmd/terraform-mcp-server@latest
  ```

  Alternatively, you can install the development version on `main`.

  ```shell-session
  $ go install github.com/hashicorp/terraform-mcp-server/cmd/terraform-mcp-server@main
  ```

1. After installation, add the following configuration to your client.

  ```json
  {
    "mcp": {
      "servers": {
        "terraform": {
          "command": "/path/to/terraform-mcp-server",
          "args": ["stdio"]
        }
      }
    }
  }
  ```

  Replace `/path/to/terraform-mcp-server` with the actual path to your downloaded binary. The binary location depends on your Go installation and `GOPATH` configuration. 
  
  Use `which terraform-mcp-server` to find the installed binary path.

## Start the server

You can use the `terraform-mcp-server` CLI and specify the transport protocol you want to use to start the server. Refer to the [transport protocols reference](/terraform/docs/tools/mcp-server/reference#transport-protocols) for more information.

Start the server in `stdio` mode. 

```shell-session
$ terraform-mcp-server stdio [--log-file /path/to/log]
```

Run the following command on the local instance to start the server in `streamable-http` mode:

```shell-session
$ terraform-mcp-server streamable-http \
  [--transport-port 8080] \
  [--transport-host 127.0.0.1] \
  [--mcp-endpoint /mcp] \
  [--log-file /path/to/log]
```

Instead of setting values manually, you can also use the supported environment variables. Refer to the [environment variables reference](/terraform/docs/tools/mcp-server/reference#environment-variables) for details.

## Next steps

- Begin prompting your AI model about Terraform configurations. Refer to [Prompt an AI model](/terraform/docs/tools/mcp-server/prompt) for guidance on effective prompting techniques.
- The server provides access to up-to-date provider documentation.
- Ask for help with specific Terraform resources and modules.
- Explore advanced configuration options for your specific deployment needs.
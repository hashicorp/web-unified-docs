---
page_title: Configure network access for Terraform Enterprise installation
description: Linux instances running Terraform Enterprise require network access to send and receive traffic. Learn how to configure network access.
---

# Configure network access

This topic describes how to configure network settings to allow Terraform to send and receive traffic. Refer to [Create deployment configuration overview](/terraform/enterprise/deploy/configuration) for an overview of the configuration process.

## Overview

You must configure the Linux instance that runs Terraform Enterprise to allow incoming network traffic across several ports. You must also configure Terraform Enterprise to access several external services so that Terraform can download and update resources.

Configure the following parameters in your deployment configuration file to configure network access:

1. Ports for ingress traffic. The Terraform binary accepts traffic from the following sources:
    - users
    - clients
    - VCS
    - metrics
    - TFE servers
1. Egress destination endpoints. To run Terraform Enterprise in an airgapped environment, you must also whitelist the domains that serve the Terraform Enterprise image from the registry.
1. For Docker deployments, you can also disable access to EC2 instance metadata service.
1. Specify any optional network settings, such cloud provider API endpoints for cost estimation.
1. Specify any specific network settings necessary for your environment, such as allowing traffic through firewalls.

Refer to [environment variables configuration reference](/terraform/enterprise/deploy/) for information about all environment variables.


## Define ingress settings

Specify the following values in your deployment configuration file to configure access into Terraform Enterprise. Refer to [Configuration reference](/terraform/enterprise/deploy/reference/configuration) for information about all configuration settings.

### Enable access from users, clients, and VCS

Specify the following variables in your deployment configuration file to enable ingress from users, clients, and the VCS:

- `TFE_HTTP_PORT`: Specifies the port for accessing Terraform Enterprise over HTTP. HTTP redirects to HTTPS. The default value is `80`.  
- `TFE_HTTPS_PORT`: Specifies the port for accessing Terraform Enterprise over HTTPS. The default is `443`. 

#### Ports for Podman

Podman does not expose privileged ports. If you are deploying to Podman, specify the variables in the `kube.yaml` pod specification file:

```yaml
- name: "TFE_HTTP_PORT"
  value: "8080"
- name: "TFE_HTTPS_PORT"
  value: "8443"
```

You must also specify the port values in the `kube.yaml` pod specification file:

```yaml
"ports":
- "containerPort": 8080
  "hostPort": 80
- "containerPort": 8443
  "hostPort": 443
- "containerPort": 9090
  "hostPort": 9090
```

#### Integrate with SaaS version control provider

To integrate with SaaS VCSs, such as GitHub.com, GitLab.com, Bitbucket Cloud, Azure DevOps Services, you must enable ingress from the public internet so that you can use inbound web hooks to reach Terraform Enterprise. Refer [Webhooks](/terraform/enterprise/vcs#webhooks) for additional information. 

You should also configure appropriate security controls, such as a web application firewall (WAF). Refer to your cloud provider documentation for instructions about deploying a WAF.

### Enable requests for metrics 

Specify the following variables in your deployment configuration file to enable Terraform Enterprise to receive requests for system metrics:

- `TFE_METRICS_HTTP_PORT`: TCP port on which Terraform Enterprise handles HTTP metrics requests. Default is `9090`.
- `TFE_METRICS_HTTPS_PORT`: TCP port on which Terraform Enterprise handles HTTPS metrics requests. Default is `9091`.

The metrics endpoints are optional. You can enable metrics collection by setting `TFE_METRICS_ENABLE` to `true`.

### Terraform Enterprise servers

If you plan to operate Terraform Enterprise in `active-active` mode, forward requests to port `8201` to enable high availability requests from Vault.  

## Define egress settings

Add the following destination endpoints to your deployment configuration file so that Terraform can connect to external services. 

### HashiCorp container registry

- `https://images.releases.hashicorp.com`: The endpoint hosts release container images.
- `https://helm.releases.hashicorp.com`: The endpoint hosts the helm chart for Kubernetes installation.

### Domains to whitelist for airgapped environments

To run Terraform Enterprise in an airgapped environment, you must also whitelist the following domains. This because the service that provides the container image is globally routable and may come from any of the regions:

- `s3-r-w.us-east-1.amazonaws.com`
- `s3-r-w.us-west-2.amazonaws.com`
- `s3-r-w.eu-central-1.amazonaws.com`
- `s3-r-w.eu-west-1.amazonaws.com`

Note that the domains are owned by Amazon, not HashiCorp, and may change at any time. Refer to this documentation to verify the domains each time you run the deployment configuration.  

### HashiCorp service APIs

Terraform Enterprise calls the following hostnames unless you have supplied a custom Terraform bundle. Refer to [Custom and Community Providers](/terraform/enterprise/run/install-software#custom-and-community-providers)
for additional information:

- `registry.terraform.io`
- `releases.hashicorp.com`
- `https://yy0ffni7mf-dsn.algolia.net/`: Specifies the API endpoint of the Terraform Registry's [Algolia](https://www.algolia.com) application. Terraform Enterprise uses Algolia to index resources in the registry and power the public search feature.
- `reporting.hashicorp.services`: Specifies the license entitlement reporting API endpoint. Refer to [Enable automated license reports](/terraform/enterprise/deploy/manage/license-report) for additional information.


### Additional outbound network targets

Terraform Enterprise also needs egress access to the following systems:

- Any VCS servers and services you that you plan to use.
- Login or authentication servers if you want to enable ADFS, Okta, or other SAML services.
- Cloud API endpoints that you intend to manage with Terraform
- Third party services that you intend to integrate or manage with the Terraform Enterprise server.

### Cost estimation APIs

When [Cost Estimation](/terraform/enterprise/application-administration/integration#cost-estimation-integration) is enabled, Terraform Enterprise uses the following cloud provider's APIs to get up-to-date pricing information:

- `api.pricing.us-east-1.amazonaws.com`
- `cloudbilling.googleapis.com`
- `prices.azure.com`

## Specify the Docker network container for run execution

In the [`TFE_RUN_PIPELINE_DOCKER_NETWORK` configuration](/terraform/enterprise/deploy/reference/configuration#tfe_run_pipeline_docker_network), specify the network address where Docker creates the container Terraform uses to execute runs. This is an optional configuration that enables you to prevent Terraform Enterprise from accessing the EC2 instance metadata service in AWS. Refer to [Disable access to EC2 instance metadata service](#disable-access-to-ec2-instance-metadata-service) for instructions.

The network must already exist and will not be created automatically. Leave blank to use the default network. Defaults to `""`.  


## Disable access to EC2 instance metadata service

1. Create a Docker network. Docker uses this network to create containers that run Terraform Enterprise. We recommend using a name that matches your deployment. The following example creates a network called `tfe-workers`:

  ```shell-session
  $ docker network create tfe-workers
  ```
  
1. Run the `docker network inspect` command to get the subnet and gateway for the Docker network:

  ```shell-session
  $ docker network inspect tfe-workers
  ```

1. Copy the subnet address from the `docker network inspect` command output so that you can use it in the IP table. In the following example, the subnet is `172.18.0.0/16`:

  ```json
  [
    {
        "Name": "tfe-workers",
        "Id": "10cd24aeba3df774ef2bf1dcb64cadbf2016160fd2cd64bb46f07595e8eb3a83",
        "Created": "2024-07-08T13:09:52.596315311-07:00",
        "Scope": "local",
        "Driver": "bridge",
        "EnableIPv6": false,
        "IPAM": {
            "Driver": "default",
            "Options": {},
            "Config": [
                {
                    "Subnet": "172.18.0.0/16",
                    "Gateway": "172.18.0.1"
                }
            ]
        },
        "Internal": false,
        "Attachable": false,
        "Ingress": false,
        "ConfigFrom": {
            "Network": ""
        },
        "ConfigOnly": false,
        "Containers": {},
        "Options": {},
        "Labels": {}
    }
  ]
  ```

1. Add a rule to the IP table that blocks Terraform Enterprise access to the EC2 instance metadata service. Specify the EC2 instance metadata service address, `169.254.169.254`, as the destination and the subnet address you copied in step 3 as the source. You can use the following command template and replace `<DOCKER_NETWORK_ADDRESS_RANGE>` with your subnet address to add the rule using the `iptables` command:

  ```shell-session
  $ iptables -I DOCKER-USER -d 169.254.169.254 -s <DOCKER_NETWORK_ADDRESS_RANGE> -j DROP
  ```

1. Ensure that the `TFE_RUN_PIPELINE_DOCKER_NETWORK` environment variable is set to the name of the Docker network you created in your Docker Compose file for deploying Terraform Enterprise. The following example sets the variable to a network named `tfe-workers`:

  ```yaml
  services:
    tfe:
      environment:
        TFE_RUN_PIPELINE_DOCKER_NETWORK: tfe-workers
    ```  

When you start Terraform Enterprise, the Terraform Enterprise container will connect to the `tfe-workers` Docker network and apply the IP table rule.

## Specify additional configuration settings

1. If a firewall is configured on the instance, run one of the following commands to allow traffic to flow out of the `docker0` interface to the instance's primary address. We recommend doing this before you install Docker.

   - To use UFW, run: `ufw allow in on docker0`
   - To use firewalld, run: `firewall-cmd --permanent --zone=trusted --change-interface=docker0`

1. Get a domain name for the instance. Using an IP address to access the product is not supported as many systems use TLS and need to verify that the certificate is correct, which can only be done with a hostname at present.

1. **For GCP only:** Configure Docker to use an MTU (maximum transmission unit) of `1460`, as required by Google ([GCP Cloud VPN Documentation: MTU Considerations](https://cloud.google.com/network-connectivity/docs/vpn/concepts/mtu-considerations)).

   To configure Docker's MTU, create an `/etc/docker/daemon.json` file with the following content:

   ```json
   {
     "mtu": 1460
   }
   ```

1. Ensure that the Docker bridge network address is not being used elsewhere on the network. If it is, refer to the [Docker documentation](https://docs.docker.com/network/bridge/) for information on how to change it.

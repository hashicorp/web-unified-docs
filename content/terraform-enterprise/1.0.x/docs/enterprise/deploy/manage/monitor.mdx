---
page_title: Monitor Terraform Enterprise deployments
description: Learn how to enable logs and metrics to monitor your Terraform Enterprise installation's performance.
---

# Monitor Terraform Enterprise

This topic describes how to enable logs and metrics in Terraform Enterprise so that you can monitor your non-Replicated deployment. For information about monitoring Replicated deployments, refer to [Terraform Enterprise Log Forwarding](/terraform/enterprise/deploy/replicated/monitoring/logging) and [Monitoring a Terraform Enterprise Instance](/terraform/enterprise/deploy/replicated/monitoring/monitoring) in the Replicated administration section.

## Overview

Complete the following steps to monitor your Terraform Enterprise deployment:

1. Enable log forwarding. Terraform Enterprise writes logs directly to standard output and standard error, which allows you to forward logs using native tooling for your deployment platform.
1. Enable metrics collection. Metrics collection is disabled by default. Update your deployment configuration file to enable metrics collection

## Enable log forwarding

Terraform Enterprise writes logs directly to standard output and standard error. This allows you to forward logs using native tooling for your deployment platform.
Terraform Enterprise logs directly to standard output and standard error. This
allows you to forward logs using native tooling for your deployment platform.

### Log location and format

The individual service logs are located within the
`/var/log/terraform-enterprise` directory inside the container.

```sh
/var/log/terraform-enterprise
├── atlas.log
├── nginx.log
├── sidekiq.log
└── vault.log
```

Each service log is a plain text file containing the logs for that service. Logs
are collated and logged to the container's standard output in JSON format. Each
log entry contains two fields:

* `component`: The name of the individual service that emitted the log entry.
* `log`: The contents of the log message.

An example set of log entries emitted by a Terraform Enterprise container would appear as follows:

```sh
{"log":"2023-09-18 02:39:05 [INFO] msg=Worker start worker=AuthenticationTokenDeletionWorker","component":"sidekiq"}
{"log":"2023-09-18T02:39:05.098Z pid=156 tid=2pos class=FailedJobWorker jid=1010d28ac591979d9decb61f INFO: start","component":"sidekiq"}
{"log":"2023-09-18 02:39:05 [INFO] msg=Worker start worker=FailedJobWorker","component":"sidekiq"}
{"log":"2023-09-18 02:39:05 [INFO] msg=Worker finish worker=AuthenticationTokenDeletionWorker","component":"sidekiq"}
{"log":"2023-09-18T02:39:05.114Z pid=156 tid=2pyc class=AuthenticationTokenDeletionWorker jid=515e8a727a3e4948e9dbb04a elapsed=0.034 INFO: done","component":"sidekiq"}
{"log":"2023-09-18 02:39:05 [INFO] agent_jobs_processed=[] agent_jobs_errored=[] msg=Worker finish worker=FailedJobWorker","component":"sidekiq"}
{"log":"2023-09-18T02:39:05.118Z pid=156 tid=2pos class=FailedJobWorker jid=1010d28ac591979d9decb61f queue=default elapsed=0.02 INFO: done","component":"sidekiq"}
{"log":"2023-09-18 02:39:13 [INFO] [3efaaec9-48d4-4517-9fde-127f80faacb4] [dd.service=atlas dd.trace_id=1904097642804464614 dd.span_id=0 ddsource=ruby] {\"method\":\"GET\",\"path\":\"/\",\"format\":\"html\",\"status\":301,\"allocations\":493,\"duration\":0.72,\"view\":0.0,\"db\":0.0,\"location\":\"https://tfe.example.com/session\",\"dd\":{\"trace_id\":\"1904097642804464614\",\"span_id\":\"0\",\"env\":\"\",\"service\":\"atlas\",\"version\":\"\"},\"ddsource\":[\"ruby\"],\"uuid\":\"3efaaec9-48d4-4517-9fde-127f80faacb4\",\"remote_ip\":\"1.2.3.4\",\"request_id\":\"3efaaec9-48d4-4517-9fde-127f80faacb4\",\"user_agent\":\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\",\"user\":null,\"auth_source\":null}","component":"atlas"}
{"log":"2023-09-18 02:39:13 [INFO] [3cb89cfa-7d7f-4aeb-9e60-2256b016a839] [dd.service=atlas dd.trace_id=4370203755142829190 dd.span_id=0 ddsource=ruby] {\"method\":\"GET\",\"path\":\"/session\",\"format\":\"html\",\"status\":200,\"allocations\":3895,\"duration\":7.3,\"view\":5.77,\"db\":0.59,\"dd\":{\"trace_id\":\"4370203755142829190\",\"span_id\":\"0\",\"env\":\"\",\"service\":\"atlas\",\"version\":\"\"},\"ddsource\":[\"ruby\"],\"uuid\":\"3cb89cfa-7d7f-4aeb-9e60-2256b016a839\",\"remote_ip\":\"1.2.3.4\",\"request_id\":\"3cb89cfa-7d7f-4aeb-9e60-2256b016a839\",\"user_agent\":\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\",\"user\":null,\"auth_source\":null}","component":"atlas"}
{"log":"1.2.3.4 - - [18/Sep/2023:02:39:13 +0000] \"GET / HTTP/1.1\" 301 117 \"-\" \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\"","component":"nginx"}
{"log":"1.2.3.4 - - [18/Sep/2023:02:39:13 +0000] \"GET /session HTTP/1.1\" 200 1735 \"-\" \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\"","component":"nginx"}
{"log":"Storing the encrypted Vault token in Redis","component":"vault"}
```

Note that the format of individual service logs is considered an internal implementation
detail and is subject to change at any release.

### External log forwarding

We strongly recommend using an external log forwarding solution that aligns with
your existing observability solutions. Depending on the deployment platform,
native or third-party solutions (e.g., host-level monitoring agents) may be an
appropriate solution for log aggregation and forwarding. Hashicorp does not provide
support for third-party log forwarding solutions.

#### Docker

Docker supports a multitude of logging drivers. See the [Docker logging
driver](https://docs.docker.com/config/containers/logging/configure/) list for what
options are available.

#### Kubernetes

Kubernetes supports several architectures for log-forwarding. See the
[Kubernetes logging architectures documentation](https://kubernetes.io/docs/concepts/cluster-administration/logging/#cluster-level-logging-architectures)
for what options are available.

### Native log forwarding

As a convenience to aid in migrating from legacy Replicated environments
to Flexible Deployments, Terraform Enterprise provides a mechanism to inject
FluentBit `[OUTPUT]` configuration directives. This allows Terraform Enterprise
to use FluentBit plugins to forward log data directly to a number of external
destinations.

FluentBit configuration must be provided the Terraform Enterprise container in
a file mounted to the container. That is, the configuration value must point to
a _filesystem path_ on the Docker container where the FluentBit configuration is
located; the configuration must _not_ contain the actual configuration itself.
This means it is the responsibility of the Terraform Enterprise operator to mount the config
snippet to the Docker container.

| **Key**                        | **Description**                                                                                     | **Specific Format Required** |
| ------------------------------ | --------------------------------------------------------------------------------------------------- | ---------------------------- |
| TFE_LOG_FORWARDING_CONFIG_PATH | Filesystem path on the Terraform Enterprise container containing FluentBit `[OUTPUT]` configuration | **Yes**, string.             |

<Note title="Future deprecation">
Exposing FluentBit configuration to Terraform Enterprise operators is provided as a convenience to
facilitate migration Terraform Enterprise installations. Customers are encouraged
to migrate away from relying on injected FluentBit configuration, and provide their
own log forwarding and aggregation solution in their infrastructure.
</Note>

#### Limitations

The FluentBit solution provided in [legacy Replicated Terraform Enterprise deployments](/terraform/enterprise/deploy/replicated/monitoring/logging)
emitted log entries that contained additional metadata keys, such as hostname and
IP address. This allowed for additional observability value from log entries, as
operators could identify the source of log entries. Unlike Replicated deployments,
logs emitted by the FluentBit plugins made available in Terraform Enterprise
Flexible Deployments do not contain additional metadata attached to each log entry.
This is due to the isolated nature of the FluentBit process within the Terraform
Enterprise Docker container; by definition, processes within the Docker container
are not exposed to host-level details.

Because of this, we strongly recommend using an external log forwarding solution
that aligns with your existing observability solutions. See [external log forwarding](#external-log-forwarding)
for further discussion.

Additionally, note that built-in log forwarding is only available for Docker-deployed
Terraform Enterprise installations. Terraform Enterprise deployed on Kubernetes
does not support leveraging the built-in FluentBit.

#### Supported external destinations

You can only forward logs to one of the supported external destinations below.
Each supported external destination contains example configuration for convenience.

@include "replicated-and-fdo/monitoring/logging/supported-destinations-partial.mdx"

## Enable metrics collection

Metrics collection is disabled by default. Set the `TFE_METRICS_ENABLE` variable to `true` in your runtime configuration. Kubernetes and Podman installations do not emit ` tfe.container.*` metrics. Refer to the [configuration reference](/terraform/enterprise/deploy/reference/configuration) for additional details.

### Access metrics

Terraform Enterprise exposes metrics on a port separate from the application. This allows operators to use network access controls to restrict access to metrics data to authorized consumers, such as a Prometheus server.

By default, metrics are exposed on the following ports:

- `9090` for HTTP.  
- `9091` for HTTPS.

You can configure the ports by setting the `TFE_METRICS_HTTP_PORT` and `TFE_METRICS_HTTPS_PORT` environment variables. Refer to the [configuration reference](/terraform/enterprise/deploy/reference/configuration) for additional details.

The HTTP and HTTPS ports serve metrics on the path `/metrics`.

By default, requests to the /metrics endpoint will emit metrics in JSON format. Use the query parameter `?format=prometheus` to emit metrics in Prometheus format.

When using Prometheus, we recommend using a scrape interval shorter than the expiration time of 15 seconds to ensure that Terraform Enterprise reports data points from short-lived processes.

Refer to the [metrics reference](/terraform/enterprise/deploy/reference/metrics) for details about the metrics Terraform Enterprise emits.
